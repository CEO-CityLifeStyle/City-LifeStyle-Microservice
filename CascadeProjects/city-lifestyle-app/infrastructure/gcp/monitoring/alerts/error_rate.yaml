displayName: High Error Rate Alert
documentation:
  content: |
    # High Error Rate Alert
    This alert triggers when the error rate exceeds the threshold.
    
    ## Investigation Steps
    1. Check error logs in Cloud Logging
    2. Review recent deployments
    3. Check service dependencies
    4. Monitor resource utilization
    
    ## Remediation Steps
    1. Rollback if related to recent deployment
    2. Scale resources if needed
    3. Check external dependencies
    4. Review error handling logic

combiner: OR
conditions:
  - displayName: "Cloud Run Error Rate > 1%"
    conditionThreshold:
      filter: >
        metric.type="run.googleapis.com/request_count"
        resource.type="cloud_run_revision"
        metric.labels.response_code_class="5xx"
      aggregations:
        - alignmentPeriod: 60s
          perSeriesAligner: ALIGN_RATE
          crossSeriesReducer: REDUCE_SUM
      comparison: COMPARISON_GT
      duration: 300s
      thresholdValue: 0.01
      trigger:
        count: 1

  - displayName: "API Gateway Error Rate > 1%"
    conditionThreshold:
      filter: >
        metric.type="apigateway.googleapis.com/request_count"
        resource.type="api_gateway"
        metric.labels.response_code_class="5xx"
      aggregations:
        - alignmentPeriod: 60s
          perSeriesAligner: ALIGN_RATE
          crossSeriesReducer: REDUCE_SUM
      comparison: COMPARISON_GT
      duration: 300s
      thresholdValue: 0.01
      trigger:
        count: 1

alertStrategy:
  autoClose: 7200s
  notificationRateLimit:
    period: 300s

notification_channels:
  - type: email
    labels:
      email_address: alerts@citylifestyle.app
  - type: slack
    labels:
      channel_name: "#alerts"
